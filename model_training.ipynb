{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install keras-tuner"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qgW26EdenNro",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741800783695,
     "user_tz": -60,
     "elapsed": 13654,
     "user": {
      "displayName": "Albert SallesTorruella",
      "userId": "17599184012787070764"
     }
    },
    "outputId": "60eda51f-889f-4564-f660-a39d230a6400"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m129.1/129.1 kB\u001B[0m \u001B[31m3.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "# 1. Load and Prepare the Data  #\n",
    "data = pd.read_csv('/content/drive/MyDrive/MTU/ai-project/creditcard.csv')\n",
    "data = data.sort_values('Time')\n",
    "\n",
    "# Extract features and labels\n",
    "features = data.drop(columns=['Class', 'Time']).values\n",
    "labels = data['Class'].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Global variable for the number of features (needed for model input shape)\n",
    "n_features = features_scaled.shape[1]\n",
    "\n",
    "# --------------------------------------#\n",
    "# 2. Function to Create Sequences       #\n",
    "# --------------------------------------#\n",
    "def create_sequences(data, labels, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length + 1):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        # Label a sequence as fraudulent if any transaction in it is fraud\n",
    "        y.append(1 if labels[i:i+seq_length].sum() > 0 else 0)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# 3. Custom HyperModel that Tunes Sequence Length     #\n",
    "#    and Other Hyperparameters                        #\n",
    "class LSTMHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        # Tune the sequence length: choose from 5, 10, or 20\n",
    "        seq_length = hp.Choice('sequence_length', [5, 10, 20])\n",
    "\n",
    "        model = Sequential()\n",
    "        # First LSTM layer\n",
    "        units1 = hp.Int('units_lstm1', min_value=32, max_value=128, step=32)\n",
    "        model.add(LSTM(units1, input_shape=(seq_length, n_features), return_sequences=True))\n",
    "        dropout1 = hp.Float('dropout1', min_value=0.1, max_value=0.5, step=0.1)\n",
    "        model.add(Dropout(dropout1))\n",
    "\n",
    "        # Second LSTM layer\n",
    "        units2 = hp.Int('units_lstm2', min_value=16, max_value=64, step=16)\n",
    "        model.add(LSTM(units2))\n",
    "        dropout2 = hp.Float('dropout2', min_value=0.1, max_value=0.5, step=0.1)\n",
    "        model.add(Dropout(dropout2))\n",
    "\n",
    "        # Dense output layer\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Tune learning rate\n",
    "        learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=[\n",
    "                'accuracy',\n",
    "                tf.keras.metrics.Precision(name='precision'),\n",
    "                tf.keras.metrics.Recall(name='recall'),\n",
    "                tf.keras.metrics.AUC(name='auc')\n",
    "            ]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        # Retrieve the chosen sequence length\n",
    "        seq_length = hp.get('sequence_length')\n",
    "        # Generate sequences using the tunable sequence length\n",
    "        X_seq, y_seq = create_sequences(features_scaled, labels, seq_length)\n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_seq, y_seq, test_size=0.2, random_state=42, stratify=y_seq\n",
    "        )\n",
    "        # Apply SMOTE on the training set\n",
    "        n_samples, seq_len, n_features_local = X_train.shape\n",
    "        X_train_flat = X_train.reshape(n_samples, seq_len * n_features_local)\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_res, y_train_res = smote.fit_resample(X_train_flat, y_train)\n",
    "        X_train_res = X_train_res.reshape(-1, seq_length, n_features_local)\n",
    "\n",
    "        return model.fit(\n",
    "            X_train_res, y_train_res,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=10,\n",
    "            batch_size=64,\n",
    "            **kwargs\n",
    "        )"
   ],
   "metadata": {
    "id": "RlJ5ISX-XDd1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741801592016,
     "user_tz": -60,
     "elapsed": 2461,
     "user": {
      "displayName": "Albert SallesTorruella",
      "userId": "17599184012787070764"
     }
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Set Up and Run the Tuner  #\n",
    "hypermodel = LSTMHyperModel()\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_auc',\n",
    "    max_trials=10,         # Increase for a more thorough search\n",
    "    executions_per_trial=1,\n",
    "    directory='hyperparam_tuning',\n",
    "    project_name='credit_card_fraud_lstm'\n",
    ")\n",
    "\n",
    "# Since our HyperModel.fit() method handles data generation,\n",
    "# we don't need to pass x and y to tuner.search().\n",
    "tuner.search()\n",
    "\n",
    "# -----------------------------#\n",
    "# 5. Evaluate the Best Model   #\n",
    "# -----------------------------#\n",
    "# Get the best hyperparameters and model\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_seq_length = best_hp.get('sequence_length')\n",
    "\n",
    "# For final evaluation, generate a test set using the best sequence length.\n",
    "X_seq_all, y_seq_all = create_sequences(features_scaled, labels, best_seq_length)\n",
    "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
    "    X_seq_all, y_seq_all, test_size=0.2, random_state=42, stratify=y_seq_all\n",
    ")\n",
    "# Apply SMOTE on the training set\n",
    "n_samples, seq_len, n_features_local = X_train_final.shape\n",
    "X_train_final_flat = X_train_final.reshape(n_samples, seq_len * n_features_local)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_final_res, y_train_final_res = smote.fit_resample(X_train_final_flat, y_train_final)\n",
    "X_train_final_res = X_train_final_res.reshape(-1, best_seq_length, n_features_local)\n",
    "\n",
    "# Retrieve the best model and evaluate on the test set\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "loss, accuracy, precision, recall, auc_metric = best_model.evaluate(X_test_final, y_test_final, verbose=0)\n",
    "print(\"Best Model Evaluation on Test Set:\")\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"AUC: {auc_metric:.4f}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qgIPbdh0ekCU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741809245023,
     "user_tz": -60,
     "elapsed": 7653005,
     "user": {
      "displayName": "Albert SallesTorruella",
      "userId": "17599184012787070764"
     }
    },
    "outputId": "f8e81b21-a3e3-4782-c959-ebbbaab2b0d8"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trial 10 Complete [00h 12m 38s]\n",
      "val_auc: 0.9920414686203003\n",
      "\n",
      "Best val_auc So Far: 0.9998045563697815\n",
      "Total elapsed time: 02h 07m 12s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Model Evaluation on Test Set:\n",
      "Loss: 0.0073\n",
      "Accuracy: 0.9978\n",
      "Precision: 0.9364\n",
      "Recall: 0.9947\n",
      "AUC: 0.9998\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# -----------------------------------------#\n",
    "# 5. Print All Trials and Best Parameters  #\n",
    "# -----------------------------------------#\n",
    "\n",
    "print(\"\\nAll Trial Results:\")\n",
    "for trial in tuner.oracle.trials.values():\n",
    "    print(f\"Trial ID: {trial.trial_id}, Score: {trial.score}, Hyperparameters: {trial.hyperparameters.values}\")\n",
    "\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(best_hp.values)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lky0GR8h1lPV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741809879595,
     "user_tz": -60,
     "elapsed": 39,
     "user": {
      "displayName": "Albert SallesTorruella",
      "userId": "17599184012787070764"
     }
    },
    "outputId": "90a1ff75-3c82-4f21-b81b-70bc62f03d1e"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "All Trial Results:\n",
      "Trial ID: 00, Score: 0.998674750328064, Hyperparameters: {'sequence_length': 10, 'units_lstm1': 96, 'dropout1': 0.30000000000000004, 'units_lstm2': 16, 'dropout2': 0.2, 'learning_rate': 0.00012337256785879854}\n",
      "Trial ID: 01, Score: 0.982997477054596, Hyperparameters: {'sequence_length': 5, 'units_lstm1': 128, 'dropout1': 0.1, 'units_lstm2': 32, 'dropout2': 0.30000000000000004, 'learning_rate': 0.00010406284012562844}\n",
      "Trial ID: 02, Score: 0.9994115829467773, Hyperparameters: {'sequence_length': 10, 'units_lstm1': 64, 'dropout1': 0.30000000000000004, 'units_lstm2': 32, 'dropout2': 0.30000000000000004, 'learning_rate': 0.0006201914963139159}\n",
      "Trial ID: 03, Score: 0.9933164119720459, Hyperparameters: {'sequence_length': 5, 'units_lstm1': 96, 'dropout1': 0.1, 'units_lstm2': 64, 'dropout2': 0.5, 'learning_rate': 0.0003987720809096887}\n",
      "Trial ID: 04, Score: 0.9992073774337769, Hyperparameters: {'sequence_length': 20, 'units_lstm1': 96, 'dropout1': 0.2, 'units_lstm2': 64, 'dropout2': 0.2, 'learning_rate': 0.00013414267455355165}\n",
      "Trial ID: 05, Score: 0.9993301630020142, Hyperparameters: {'sequence_length': 20, 'units_lstm1': 64, 'dropout1': 0.2, 'units_lstm2': 64, 'dropout2': 0.30000000000000004, 'learning_rate': 0.002570345329777908}\n",
      "Trial ID: 06, Score: 0.9998045563697815, Hyperparameters: {'sequence_length': 20, 'units_lstm1': 64, 'dropout1': 0.4, 'units_lstm2': 32, 'dropout2': 0.2, 'learning_rate': 0.002220709089529535}\n",
      "Trial ID: 07, Score: 0.9994096159934998, Hyperparameters: {'sequence_length': 10, 'units_lstm1': 128, 'dropout1': 0.1, 'units_lstm2': 64, 'dropout2': 0.4, 'learning_rate': 0.0004685026687138719}\n",
      "Trial ID: 08, Score: 0.9995061755180359, Hyperparameters: {'sequence_length': 20, 'units_lstm1': 128, 'dropout1': 0.1, 'units_lstm2': 64, 'dropout2': 0.30000000000000004, 'learning_rate': 0.0047156844970391324}\n",
      "Trial ID: 09, Score: 0.9920414686203003, Hyperparameters: {'sequence_length': 5, 'units_lstm1': 64, 'dropout1': 0.30000000000000004, 'units_lstm2': 64, 'dropout2': 0.30000000000000004, 'learning_rate': 0.0005618333446427555}\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'sequence_length': 20, 'units_lstm1': 64, 'dropout1': 0.4, 'units_lstm2': 32, 'dropout2': 0.2, 'learning_rate': 0.002220709089529535}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "best_model.save('/content/drive/MyDrive/MTU/ai-project/best_lstm_model.keras')"
   ],
   "metadata": {
    "id": "9d0OY9ov9Zr_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741810334399,
     "user_tz": -60,
     "elapsed": 65,
     "user": {
      "displayName": "Albert SallesTorruella",
      "userId": "17599184012787070764"
     }
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('/content/drive/MyDrive/MTU/ai-project/best_lstm_model.keras')\n",
    "\n",
    "# Check the model architecture\n",
    "loaded_model.summary()\n"
   ],
   "metadata": {
    "id": "i1J5uGUFZQB4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741810365520,
     "user_tz": -60,
     "elapsed": 138,
     "user": {
      "displayName": "Albert SallesTorruella",
      "userId": "17599184012787070764"
     }
    },
    "outputId": "52e61398-9985-4a1a-917b-37a2b3b5d477"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 10 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                        \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape               \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m        Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m64\u001B[0m)              │          \u001B[38;5;34m24,064\u001B[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)                    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m64\u001B[0m)              │               \u001B[38;5;34m0\u001B[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001B[38;5;33mLSTM\u001B[0m)                        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)                  │          \u001B[38;5;34m12,416\u001B[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)                  │               \u001B[38;5;34m0\u001B[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)                   │              \u001B[38;5;34m33\u001B[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,064</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m73,028\u001B[0m (285.27 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">73,028</span> (285.27 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m36,513\u001B[0m (142.63 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,513</span> (142.63 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m36,515\u001B[0m (142.64 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,515</span> (142.64 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_privacy.privacy.membership_inference_attack import membership_inference_attack as mia\n",
    "from tensorflow_privacy.privacy.membership_inference_attack import attack_input_data\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "HpDe12fFEgT2",
    "executionInfo": {
     "status": "error",
     "timestamp": 1741811844098,
     "user_tz": -60,
     "elapsed": 78,
     "user": {
      "displayName": "Albert SallesTorruella",
      "userId": "17599184012787070764"
     }
    },
    "outputId": "555bee46-c2e2-4b7b-a3fb-b2fdeb34f66d",
    "ExecuteTime": {
     "end_time": "2025-03-13T19:34:53.815114Z",
     "start_time": "2025-03-13T19:34:53.679801Z"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "dlopen(/opt/miniconda3/envs/ds/lib/python3.9/site-packages/tensorflow-plugins/libmetal_plugin.dylib, 0x0006): symbol not found in flat namespace '__ZN10tensorflow8internal10LogMessage16VmoduleActivatedEPKci'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_privacy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprivacy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmembership_inference_attack\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m membership_inference_attack \u001B[38;5;28;01mas\u001B[39;00m mia\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_privacy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprivacy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmembership_inference_attack\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m attack_input_data\n",
      "File \u001B[0;32m/opt/miniconda3/envs/ds/lib/python3.9/site-packages/tensorflow/__init__.py:438\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    436\u001B[0m _plugin_dir \u001B[38;5;241m=\u001B[39m _os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(_s, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensorflow-plugins\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(_plugin_dir):\n\u001B[0;32m--> 438\u001B[0m   \u001B[43m_ll\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_library\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_plugin_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    439\u001B[0m   \u001B[38;5;66;03m# Load Pluggable Device Library\u001B[39;00m\n\u001B[1;32m    440\u001B[0m   _ll\u001B[38;5;241m.\u001B[39mload_pluggable_device_library(_plugin_dir)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/ds/lib/python3.9/site-packages/tensorflow/python/framework/load_library.py:151\u001B[0m, in \u001B[0;36mload_library\u001B[0;34m(library_location)\u001B[0m\n\u001B[1;32m    148\u001B[0m     kernel_libraries \u001B[38;5;241m=\u001B[39m [library_location]\n\u001B[1;32m    150\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m lib \u001B[38;5;129;01min\u001B[39;00m kernel_libraries:\n\u001B[0;32m--> 151\u001B[0m     \u001B[43mpy_tf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTF_LoadLibrary\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlib\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    154\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[1;32m    155\u001B[0m       errno\u001B[38;5;241m.\u001B[39mENOENT,\n\u001B[1;32m    156\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe file or folder to load kernel libraries from does not exist.\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    157\u001B[0m       library_location)\n",
      "\u001B[0;31mNotFoundError\u001B[0m: dlopen(/opt/miniconda3/envs/ds/lib/python3.9/site-packages/tensorflow-plugins/libmetal_plugin.dylib, 0x0006): symbol not found in flat namespace '__ZN10tensorflow8internal10LogMessage16VmoduleActivatedEPKci'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow_privacy"
   ],
   "metadata": {
    "id": "PhUPsjKbE4Nt",
    "ExecuteTime": {
     "end_time": "2025-03-13T19:40:29.339623Z",
     "start_time": "2025-03-13T19:40:29.112418Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_privacy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow_privacy\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow_privacy'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "mount_file_id": "1mJtX38Y9103-VU3j4l9xT5sEKs-FWCLl",
   "authorship_tag": "ABX9TyOMmETxQD2d7KiUpjSDU1F1"
  },
  "kernelspec": {
   "name": "ds",
   "language": "python",
   "display_name": "ds"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
